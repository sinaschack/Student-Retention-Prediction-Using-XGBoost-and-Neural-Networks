# Student-Retention-Prediction-Using-XGBoost-and-Neural-Networks
Predict student dropout using supervised learning with XGBoost and neural networks. Features data preprocessing, feature engineering, model tuning, evaluation, and actionable insights for early interventions.

## Project Overview

This project applies **supervised learning techniques** to predict student dropout risk in international education programs. Using **XGBoost and Neural Networks**, the analysis identifies at-risk students early, enabling timely interventions and data-driven decisions to improve retention and academic outcomes.

The project demonstrates skills in data preprocessing, feature engineering, model training and evaluation, hyperparameter tuning, and interpretation of results for actionable insights.

## Data

**The dataset includes student demographics, engagement, and academic performance across three stages of the study journey. Key features include age, gender, nationality, course information, attendance, and assessment results.**

**This dataset is 100% synthetic and was generated solely for demonstration purposes.**

It does NOT contain any real data and has absolutely no resemblance to the original dataset, which is protected under a Non-Disclosure Agreement (NDA). All values, names, and attributes in this dataset are fictitious and do not represent any real individuals, organizations, or proprietary information.

## Approach

The analysis follows these steps:

### Data Preprocessing and Cleaning

* Handle missing values and duplicates
* Remove anomalies using statistical methods and machine learning (**Isolation Forest**)

### Feature Engineering

* Derive new features like module completion counts and attendance rates

### Exploratory Data Analysis (EDA)

* Visualize distributions and feature relationships
* Identify patterns and correlations relevant to dropout risk

### Modeling

* Train **XGBoost** and **Neural Network** models
* Optimize hyperparameters with tuning techniques (**Optuna**, **Keras Tuner**)
* Evaluate using accuracy, AUC, confusion matrix, precision, recall, and F1-score

### Dimensionality Reduction and Visualization

* Use **PCA** and **t-SNE** for model interpretation and cluster analysis

### Insights

* Identify at-risk students across different academic stages
* Highlight key predictive features and trends

## Key Skills Demonstrated

* Supervised machine learning: **XGBoost**, **Neural Networks**
* Data preprocessing, feature engineering, and handling imbalanced datasets
* Model evaluation and hyperparameter optimization
* Dimensionality reduction and visualization (**PCA**, **t-SNE**)
* Actionable insights for decision-making
